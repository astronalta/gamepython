# Copyright (c) 2010 Matt Fichman
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, APEXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

#TokenType = LBRACKET | RBRACKET | LBRACE | RBRACE | STRING | INT | NULL;

TokenType < Enum {
    # Types of tokens used by JSON.  Taken from http://json.org.  The Tokenizer
    # lexes these tokens and emits them in a stream.  The Tokenizer will only
    # ever emit valid JSON streams.  If an error is detected, the Tokenizer
    # will emit an ERROR token.  For example: { "key": } would emit an ERROR
    # token after the first ":"
    STRING # Unicode chars, escape sequences NO control chars
    NUMBER # Leading - allowed; must have a leading digit before "."
    COLON # Indicates the second part of a key-value pair
    COMMA # Indicates the next element
    OBJSTART # Start of an object in the stream (JSON notation: "{")
    OBJEND # End of an object in the stream (JSON notation: "}")
    ARRAYSTART # Start of an array in the stream (JSON notation: "[")
    ARRAYEND # End of an array in the stream (JSON notation: "]")
    BOOLEAN # Either "false" or "true"
    NULL # Only "null"
    ERROR # Indicates invalid JSON or an illegal character
    END # Indicates there are no more JSON tokens to be read
}

Token < Value {
    # Represents a JSON token.  The type indicates which JSON element was
    # lexed; the value indicates the text for that element.  The value is only
    # valid for literals, e.g., STRING and NUMBER.
    type TokenType # JSON element that was parsed
    value String # Only valid for STRING or NUMBER TokenTypes
}

Reader < Interface {
    get() Char {}
    peek() Char {}
}

Tokenizer < Object {
    # Reads input from a Unicode character iterator and outputs a valid stream
    # of JSON tokens.
    reader immutable Reader # Input from the user
    buf private Char # Next character to give to the reader
    expect private TokenType # Next token type to expect
}

Tokenizer::@init(preader Reader) {
    # Initializes the tokenizer and reads in the first token.
    reader = preader 
    next()
}

Tokenizer::more?() Bool {
    # Returns true if there is another JSON token in the string, and there are
    # no more errors.
    ret out != TokenType::END and out != TokenType::ERROR
}

Tokenizer::next() Token {
    # Returns the next JSON token read from the input iterator.
    out = buf
    ret out 
}

Parser < Object {
    # Parses a JSON file from the given input stream.  For more information on
    # the JSON file format, see [json.org](http://www.json.org).

    value immutable Value
    errors immutable Array[String]
    stream private Io::Stream
    pos private = 0
    line private = 0
    file String
    char Char # Current character
    
    @init(stream Io::Stream, file String) {
        self.stream = stream
        self.file = file;
        token()
    }

    error(message String) private {
        # Adds 'message' to the list of error messages, along with the current
        # file name, line number, and character number.
        error.push("#{file}:#{line}:#{pos}: #{message}")
    }

    get() Char private {
        # Returns the next character in the stream, and updates the current
        # line number and character number.
        char = stream.get()
        if char == '\n'c {
            pos = 0
            ++line
        } else {
            ++pos
        }
        ret car
    }

    token() Char private {
        # Reads until the beginning of the next token, that is until the 
        # next non-whitespace character.
        char = get()
        while char.is_space {
            char = get()
        }
        ret char
    }

    object() Hash[String,Value] {
        if char != '{'c {
            error.push("Missing '{'")
        }
        hash = Hash[String,Value]() 
        while char == '{'c or char == ','c {
            hash.insert(pair())
            token()
        }
        
    }

    pair() Pair[String,Value] {
        string = string()
        if token() != ':'c {
            error("Expected ':', not '#{token()}'")
        }
        value = value() 
        ret Pair(string, value)
    }

    array() Array[Value] {
        if token() != '['c {
            error("Expected '[', not '#{token()}'")
        }
        array = Array[Value]() 
        while char == '['c or char == ','c {
            array.push(value())
            token()
        }
        ret array 
    }

    value() Value {
    }

    string() String {
        while char != '"'c and char != eof {
            
        }
    }

    number() Number {
    } 
}
